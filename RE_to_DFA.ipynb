{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import json \n",
    "from typing import List \n",
    "from graphviz import Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper Functions \n",
    " \n",
    "'''\n",
    "def split_input(input: str):\n",
    "    split_list = []\n",
    "    opening_match_found = False \n",
    "    match = \"\"\n",
    "    for char in input: \n",
    "        if char == '[' :\n",
    "            opening_match_found = True \n",
    "        elif char == ']': \n",
    "            opening_match_found = False \n",
    "            split_list.append('['+ match +']')\n",
    "            match = \"\" \n",
    "        elif  opening_match_found == 0 :\n",
    "            split_list.append (char) \n",
    "        else : \n",
    "            match =  match + char \n",
    "    return split_list\n",
    "\n",
    "def visualize_nfa(nfa_json):\n",
    "    # Create a new directed graph\n",
    "    dot = Digraph(format='png')\n",
    "    \n",
    "    # Set global graph attributes for visual clarity\n",
    "    dot.attr(rankdir='LR')  # Left to right layout\n",
    "\n",
    "    # Add states to the graph\n",
    "    start_state = nfa_json.get(\"startingState\")\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Determine if this state is an accepting state\n",
    "        is_accepting = state_info[\"isTerminatingState\"]\n",
    "\n",
    "        # Customize node style based on state type\n",
    "        if state_name == start_state:\n",
    "            dot.node(state_name, shape='circle', color='green', label=state_name)  # Start state\n",
    "        elif is_accepting:\n",
    "            dot.node(state_name, shape='doublecircle', color='blue', label=state_name)  # Accepting state\n",
    "        else:\n",
    "            dot.node(state_name, shape='circle', label=state_name)\n",
    "\n",
    "    # Add transitions\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Iterate over transitions and add them as edges\n",
    "        for input_symbol, destinations in state_info.items():\n",
    "            if input_symbol == \"isTerminatingState\":\n",
    "                continue\n",
    "            \n",
    "            if isinstance(destinations, list):\n",
    "                # If there are multiple destinations, create separate edges for each\n",
    "                for destination in destinations:\n",
    "                    label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                    dot.edge(state_name, destination, label=label)\n",
    "            else:\n",
    "                # Single destination, normal case\n",
    "                label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                dot.edge(state_name, destinations, label=label)\n",
    "\n",
    "    # Render and view the graph\n",
    "    dot.render('nfa_graph', view=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "This preporcessing is applied to the regex before applying shunting yard algorithm in order to : \n",
    "1) reduce all the regex to these operations only ( * , | , parenthes , concat )\n",
    "2) add a concatination symbol between characters to be recognized by the algorithm as an operator \n",
    "3) replace every [match] with one char to be treated as other alphanumeric \n",
    "'''  \n",
    "def preprocessing(input : str) :\n",
    "# input= 'a?a((cd)|(a|b))b+bb' \n",
    "    #Step1: Replace zero or one symbol '?'\n",
    "    step_1 = re.sub(r'(\\w)\\?', r'(\\1|~)', input)\n",
    "    #Step2: Replace one or more symbol '+'\n",
    "    step_2 = re.sub(r'(\\w)\\+', r'\\1\\1*', step_1)\n",
    "    #Step3: Add concat symbol before every [ or (  if they are not at the start of the regex and they are not preceded by ?\n",
    "    pattern_before = re.compile(r'''\n",
    "        (?<!^)      # Negative lookbehind assertion to ensure the position is not at the start of the string\n",
    "        (?<!\\?)     # Negative lookbehind assertion to ensure the position is not preceded by '?'\n",
    "        (?=[\\[\\(])  # Positive lookahead assertion to match '[' or '(' without consuming them\n",
    "    ''', re.VERBOSE)\n",
    "    step_3 = pattern_before.sub('?', step_2) \n",
    "    #Step 4: Add concat symbol after every ] or ) if they are not the end of regex OR they are not followed by * and not followed by ? \n",
    "    pattern_after = re.compile(r'''\n",
    "        (?<=[\\]\\)])  # Positive lookbehind assertion to match ']' or ')' without consuming them\n",
    "        (?!$)        # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\*\\?])   # Negative lookahead assertion to ensure the position is not followed by '*' or '?'\n",
    "    ''', re.VERBOSE)\n",
    "    step_4 = pattern_after.sub('?', step_3)\n",
    "    #Step 5 : Add concat after every * if its not the end of regex and its not follwed by star \n",
    "    pattern_star = re.compile(r'''\n",
    "        \\*          # Match the '*' character\n",
    "        (?!$)       # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\?])    # Negative lookahead assertion to ensure the position is not followed by '?'                      \n",
    "    ''', re.VERBOSE)\n",
    "    step_5 = pattern_star.sub('*?', step_4)\n",
    "    #Step 6 : Add concat after every alphanum or dot if its followed by alphanumeric or dot \n",
    "    pattern_alnum_dot = re.compile(r'''\n",
    "        ([a-zA-Z0-9\\.])  # Match any alphanumeric character or dot\n",
    "        (?=[a-zA-Z0-9\\.])  # Positive lookahead assertion to ensure it is followed by another alphanumeric character or dot\n",
    "    ''', re.VERBOSE)\n",
    "    step_6 = pattern_alnum_dot.sub(r'\\1?', step_5)\n",
    "    return split_input(step_6) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Postfix notation removes the need for parentheses and allows computer programs to read in \n",
    "mathematical expressions one symbol after the other, instead of worrying about operator precedence \n",
    "and parentheses during computation. \n",
    "\n",
    "'''\n",
    "def shuntingYard(input) :\n",
    "    precedence_dict = {'*': 3, '?': 2, '|': 1}\n",
    "    out =[]\n",
    "    operator_stack = []\n",
    "    for char in input :\n",
    "        # If the input is alphanumeric then append to the output regex \n",
    "        if char.isalnum() or char == '.' or len(char) > 1 :\n",
    "            out.append(char)\n",
    "        # If the input is an operator\n",
    "        elif  char in precedence_dict.keys() :\n",
    "            # The first operator in the stack \n",
    "            if len(operator_stack) == 0:\n",
    "                operator_stack.append(char) \n",
    "            #  Any operator shouldn't be compared to an opening parenthes , if an opening parenthes is on the top of the stack Just add the char to the stack directly \n",
    "            elif operator_stack[-1] =='('or precedence_dict[ operator_stack[-1] ] < precedence_dict[char] :\n",
    "                operator_stack.append(char)\n",
    "            # If the operator on the top of the stack is the same as the current char then pop one to the output regex and leave the other in tha stack \n",
    "            # If two consecutive opening parenthes comes we need them both to be in the stack and not popped to the output because they will be deleted later \n",
    "            elif operator_stack[-1] != '(' and precedence_dict[ operator_stack[-1] ] == precedence_dict[char] : \n",
    "                out.append(char) \n",
    "            #If the operator at the top of the stack has higher precedence that the current operator then pop to the output until we can push the current operator to the stack \n",
    "            else : \n",
    "                while (len(operator_stack)>0 and operator_stack[-1] != '('and precedence_dict[ operator_stack[-1] ]  >= precedence_dict[char]) :\n",
    "                    popped_operator = operator_stack.pop()\n",
    "                    out.append(popped_operator)\n",
    "                operator_stack.append(char) \n",
    "        elif char == '(' :\n",
    "            operator_stack.append(char)\n",
    "        # The current char is closing parenthes -> pop from the operator stack to the output until you reach an opening parenthes\n",
    "        elif char == ')' :\n",
    "            while operator_stack:\n",
    "                operator = operator_stack.pop()\n",
    "                if operator == '(':\n",
    "                    break\n",
    "                out.append(operator)\n",
    "        # print (\"parsing char :\",char,\"output:\",out,\"stack\",operator_stack)\n",
    "        # print(\"************************\")\n",
    "    out.extend(operator_stack[::-1]) \n",
    "    # print (\"Final out :\",out)\n",
    "    return out \n",
    "\n",
    "    # print(\"Final stack :\",operator_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datastructures defined\n",
    " \n",
    "'''\n",
    "class Transition:\n",
    "    def __init__(self, destination , input):\n",
    "        self.destination = destination\n",
    "        self.input = input\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Transition(destination={self.destination.state_name}, input='{self.input}')\"\n",
    "\n",
    "\n",
    "class State:\n",
    "    state_counter = 0  \n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_name = 'S'+ str(State.state_counter) \n",
    "        State.state_counter += 1\n",
    "        self.transitions = [] \n",
    "        self.isTerminatingState = False \n",
    "\n",
    "    def add_transition(self, destination, input):\n",
    "        self.transitions.append(Transition(destination, input))\n",
    "\n",
    "    def to_dict(self):\n",
    "        state_dict = {\n",
    "            \"isTerminatingState\": self.isTerminatingState\n",
    "        }\n",
    "        for transition in self.transitions:\n",
    "            if transition.input in state_dict:\n",
    "                # If key already exists, append to the list of destinations\n",
    "                if isinstance(state_dict[transition.input], list):\n",
    "                    state_dict[transition.input].append(transition.destination.state_name)\n",
    "                else:\n",
    "                    # If it's not already a list, make it a list\n",
    "                    state_dict[transition.input] = [state_dict[transition.input], transition.destination.state_name]\n",
    "            else:\n",
    "                # If key doesn't exist, add it\n",
    "                state_dict[transition.input] = transition.destination.state_name\n",
    "        return state_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "class NFA:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.start_state:State = None \n",
    "        #TODO : is this list or one element \n",
    "        self.accept_states : List [State] = []\n",
    "    def add_states(self, states):\n",
    "        self.states.extend(states)\n",
    "        if not self.start_state and states:\n",
    "            self.start_state = states[0]\n",
    "        if states:\n",
    "            self.accept_states.append(states[-1])\n",
    "        \n",
    "    def add_state(self, state , is_start = False , is_accept = False  ):\n",
    "        self.states.append(state)\n",
    "        if is_start:\n",
    "            self.start_state = state\n",
    "        if is_accept:\n",
    "            self.accept_states.append(state)\n",
    "        return state\n",
    "    \n",
    "    def to_dict(self):\n",
    "        nfa_dict = {\n",
    "            \"startingState\": self.start_state.state_name if self.start_state else None\n",
    "        }\n",
    "        for state in self.states:\n",
    "            nfa_dict[state.state_name] = state.to_dict()\n",
    "        return nfa_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"startingState\": \"S4\",\n",
      "  \"S4\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"~\": [\n",
      "      \"S0\",\n",
      "      \"S2\"\n",
      "    ]\n",
      "  },\n",
      "  \"S5\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S0\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"a\": \"S1\"\n",
      "  },\n",
      "  \"S1\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"~\": \"S5\"\n",
      "  },\n",
      "  \"S2\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"b\": \"S3\"\n",
      "  },\n",
      "  \"S3\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"~\": \"S5\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"startingState\": \"S4\",\n",
      "  \"S4\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"~\": [\n",
      "      \"S0\",\n",
      "      \"S2\"\n",
      "    ]\n",
      "  },\n",
      "  \"S5\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S0\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"a\": \"S1\"\n",
      "  },\n",
      "  \"S1\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"~\": \"S5\"\n",
      "  },\n",
      "  \"S2\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"b\": \"S3\"\n",
      "  },\n",
      "  \"S3\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"~\": \"S5\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Finally : Thomsons construction Algorithm \n",
    "'''\n",
    "\n",
    "def alphanumeric_nfa(char) : \n",
    "    start_state = State() \n",
    "    end_state = State() \n",
    "    end_state.isTerminatingState = True \n",
    "    start_state.add_transition(end_state , char)\n",
    "    nfa = NFA() \n",
    "    nfa.add_state(start_state , is_start = True )\n",
    "    nfa.add_state(end_state , is_start = False , is_accept = True) \n",
    "    \n",
    "    return nfa \n",
    "def zero_or_more_nfa(operand: NFA) : \n",
    "    old_end_state = operand.accept_states[0]\n",
    "    old_end_state.isTerminatingState = False \n",
    "    old_start_state = operand.start_state\n",
    "    new_start_state = State() \n",
    "    new_end_state = State()  \n",
    "    new_end_state.isTerminatingState = True \n",
    "    new_start_state.add_transition(old_start_state , '~')\n",
    "    new_start_state.add_transition(new_end_state ,'~')\n",
    "    old_end_state.add_transition(old_start_state ,'~')\n",
    "    old_end_state.add_transition(new_end_state,'~')\n",
    "    nfa = NFA ()\n",
    "    nfa.add_states([new_start_state , old_start_state ,old_end_state ,new_end_state])\n",
    "    return nfa\n",
    "\n",
    "def union_nfa(operand1: NFA , operand2: NFA) :\n",
    "    new_start_state = State() \n",
    "    new_end_state = State() \n",
    "    new_end_state.isTerminatingState = True\n",
    "    new_start_state.add_transition(operand1.start_state , '~')\n",
    "    new_start_state.add_transition(operand2.start_state , '~')\n",
    "    operand1.accept_states[0].add_transition(new_end_state , '~')\n",
    "    operand2.accept_states[0].add_transition(new_end_state , '~')\n",
    "    nfa = NFA()\n",
    "    nfa.add_states([new_start_state , new_end_state])\n",
    "    nfa.add_states(operand1.states)\n",
    "    nfa.add_states(operand2.states)\n",
    "    return nfa\n",
    "def constructNFA(input ) : \n",
    "    stack_NFA = []\n",
    "    for char in input : \n",
    "        if char.isalnum() or char == '~' : \n",
    "            stack_NFA.append(alphanumeric_nfa(char))  \n",
    "        elif char == '*':\n",
    "            stack_NFA.append(zero_or_more_nfa(stack_NFA.pop()))\n",
    "        elif char == '|': \n",
    "            operand2 = stack_NFA.pop() \n",
    "            operand1 = stack_NFA.pop()\n",
    "            stack_NFA.append(union_nfa(operand1, operand2))\n",
    "            \n",
    "        # elif char == '?' :\n",
    "\n",
    "    return stack_NFA \n",
    "\n",
    "def ThomsonsConstruction (input : str) -> NFA : \n",
    "    preprocessed = preprocessing(input) \n",
    "    shunting_yard = shuntingYard(preprocessed)\n",
    "    return constructNFA(shunting_yard)  \n",
    "nfa_result = ThomsonsConstruction('a|b')\n",
    "for nfa in nfa_result: \n",
    "    # Get the JSON object from the `to_dict` method\n",
    "    nfa_json = nfa.to_dict()\n",
    "\n",
    "    # Print the JSON-formatted string\n",
    "    print(json.dumps(nfa_json, indent=2))\n",
    "    # visualize_nfa(nfa_json)\n",
    "    print(nfa) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
