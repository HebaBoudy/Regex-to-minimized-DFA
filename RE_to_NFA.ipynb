{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import json \n",
    "from typing import List , Union , Dict , Set ,Tuple, Optional\n",
    "from graphviz import Digraph\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper Functions \n",
    " \n",
    "'''\n",
    "def split_input(input: str):\n",
    "    split_list = []\n",
    "    opening_match_found = False \n",
    "    match = \"\"\n",
    "    for char in input: \n",
    "        if char == '[' :\n",
    "            opening_match_found = True \n",
    "        elif char == ']': \n",
    "            opening_match_found = False \n",
    "            split_list.append('['+ match +']')\n",
    "            match = \"\" \n",
    "        elif  opening_match_found == 0 :\n",
    "            split_list.append (char) \n",
    "        else : \n",
    "            match =  match + char \n",
    "    return split_list\n",
    "\n",
    "def visualize_nfa(nfa_json):\n",
    "    # Create a new directed graph\n",
    "    dot = Digraph(format='png')\n",
    "    \n",
    "    # Set global graph attributes for visual clarity\n",
    "    dot.attr(rankdir='LR')  # Left to right layout\n",
    "\n",
    "    # Add states to the graph\n",
    "    start_state = nfa_json.get(\"startingState\")\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Determine if this state is an accepting state\n",
    "        is_accepting = state_info[\"isTerminatingState\"]\n",
    "\n",
    "        # Customize node style based on state type\n",
    "        if state_name == start_state:\n",
    "            dot.node(state_name, shape='circle', color='green', label=state_name)  # Start state\n",
    "        elif is_accepting:\n",
    "            dot.node(state_name, shape='doublecircle', color='blue', label=state_name)  # Accepting state\n",
    "        else:\n",
    "            dot.node(state_name, shape='circle', label=state_name)\n",
    "\n",
    "    # Add transitions\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Iterate over transitions and add them as edges\n",
    "        for input_symbol, destinations in state_info.items():\n",
    "            if input_symbol == \"isTerminatingState\":\n",
    "                continue\n",
    "            \n",
    "            if isinstance(destinations, list):\n",
    "                # If there are multiple destinations, create separate edges for each\n",
    "                for destination in destinations:\n",
    "                    label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                    dot.edge(state_name, destination, label=label)\n",
    "            else:\n",
    "                # Single destination, normal case\n",
    "                label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                dot.edge(state_name, destinations, label=label)\n",
    "\n",
    "    # Render and view the graph\n",
    "    dot.render('nfa_graph', view=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "This preporcessing is applied to the regex before applying shunting yard algorithm in order to : \n",
    "1) reduce all the regex to these operations only ( * , | , parenthes , concat )\n",
    "2) add a concatination symbol between characters to be recognized by the algorithm as an operator \n",
    "3) replace every [match] with one char to be treated as other alphanumeric \n",
    "'''  \n",
    "def preprocessing(input : str) :\n",
    "# input= 'a?a((cd)|(a|b))b+bb' \n",
    "    #Step1: Replace zero or one symbol '?'\n",
    "    step_1 = re.sub(r'(\\w)\\?', r'(\\1|~)', input)\n",
    "    #Step2: Replace one or more symbol '+'\n",
    "    step_2 = re.sub(r'(\\w)\\+', r'\\1\\1*', step_1)\n",
    "    #Step3: Add concat symbol before every [ or (  if they are not at the start of the regex and they are not preceded by ?\n",
    "    pattern_before = re.compile(r'''\n",
    "        (?<!^)      # Negative lookbehind assertion to ensure the position is not at the start of the string\n",
    "        (?<!\\?)     # Negative lookbehind assertion to ensure the position is not preceded by '?'\n",
    "        (?=[\\[\\(])  # Positive lookahead assertion to match '[' or '(' without consuming them\n",
    "    ''', re.VERBOSE)\n",
    "    step_3 = pattern_before.sub('?', step_2) \n",
    "    #Step 4: Add concat symbol after every ] or ) if they are not the end of regex OR they are not followed by * and not followed by ? \n",
    "    pattern_after = re.compile(r'''\n",
    "        (?<=[\\]\\)])  # Positive lookbehind assertion to match ']' or ')' without consuming them\n",
    "        (?!$)        # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\*\\?])   # Negative lookahead assertion to ensure the position is not followed by '*' or '?'\n",
    "    ''', re.VERBOSE)\n",
    "    step_4 = pattern_after.sub('?', step_3)\n",
    "    #Step 5 : Add concat after every * if its not the end of regex and its not follwed by star \n",
    "    pattern_star = re.compile(r'''\n",
    "        \\*          # Match the '*' character\n",
    "        (?!$)       # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\?])    # Negative lookahead assertion to ensure the position is not followed by '?'                      \n",
    "    ''', re.VERBOSE)\n",
    "    step_5 = pattern_star.sub('*?', step_4)\n",
    "    #Step 6 : Add concat after every alphanum or dot if its followed by alphanumeric or dot \n",
    "    pattern_alnum_dot = re.compile(r'''\n",
    "        ([a-zA-Z0-9\\.])  # Match any alphanumeric character or dot\n",
    "        (?=[a-zA-Z0-9\\.])  # Positive lookahead assertion to ensure it is followed by another alphanumeric character or dot\n",
    "    ''', re.VERBOSE)\n",
    "    step_6 = pattern_alnum_dot.sub(r'\\1?', step_5)\n",
    "    return split_input(step_6) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Postfix notation removes the need for parentheses and allows computer programs to read in \n",
    "mathematical expressions one symbol after the other, instead of worrying about operator precedence \n",
    "and parentheses during computation. \n",
    "\n",
    "'''\n",
    "def shuntingYard(input) :\n",
    "    precedence_dict = {'*': 3, '?': 2, '|': 1}\n",
    "    out =[]\n",
    "    operator_stack = []\n",
    "    for char in input :\n",
    "        # If the input is alphanumeric then append to the output regex \n",
    "        if char.isalnum() or char == '.' or len(char) > 1 :\n",
    "            out.append(char)\n",
    "        # If the input is an operator\n",
    "        elif  char in precedence_dict.keys() :\n",
    "            # The first operator in the stack \n",
    "            if len(operator_stack) == 0:\n",
    "                operator_stack.append(char) \n",
    "            #  Any operator shouldn't be compared to an opening parenthes , if an opening parenthes is on the top of the stack Just add the char to the stack directly \n",
    "            elif operator_stack[-1] =='('or precedence_dict[ operator_stack[-1] ] < precedence_dict[char] :\n",
    "                operator_stack.append(char)\n",
    "            # If the operator on the top of the stack is the same as the current char then pop one to the output regex and leave the other in tha stack \n",
    "            # If two consecutive opening parenthes comes we need them both to be in the stack and not popped to the output because they will be deleted later \n",
    "            elif operator_stack[-1] != '(' and precedence_dict[ operator_stack[-1] ] == precedence_dict[char] : \n",
    "                out.append(char) \n",
    "            #If the operator at the top of the stack has higher precedence that the current operator then pop to the output until we can push the current operator to the stack \n",
    "            else : \n",
    "                while (len(operator_stack)>0 and operator_stack[-1] != '('and precedence_dict[ operator_stack[-1] ]  >= precedence_dict[char]) :\n",
    "                    popped_operator = operator_stack.pop()\n",
    "                    out.append(popped_operator)\n",
    "                operator_stack.append(char) \n",
    "        elif char == '(' :\n",
    "            operator_stack.append(char)\n",
    "        # The current char is closing parenthes -> pop from the operator stack to the output until you reach an opening parenthes\n",
    "        elif char == ')' :\n",
    "            while operator_stack:\n",
    "                operator = operator_stack.pop()\n",
    "                if operator == '(':\n",
    "                    break\n",
    "                out.append(operator)\n",
    "        # print (\"parsing char :\",char,\"output:\",out,\"stack\",operator_stack)\n",
    "        # print(\"************************\")\n",
    "    out.extend(operator_stack[::-1]) \n",
    "    # print (\"Final out :\",out)\n",
    "    return out \n",
    "\n",
    "    # print(\"Final stack :\",operator_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datastructures defined\n",
    " \n",
    "'''\n",
    "class Transition:\n",
    "    def __init__(self, destination , input):\n",
    "        self.destination = destination\n",
    "        self.input = input\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Transition(destination={self.destination.state_name}, input='{self.input}')\"\n",
    "\n",
    "\n",
    "class State:\n",
    "    state_counter = 0  \n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_name = 'S'+ str(State.state_counter) \n",
    "        State.state_counter += 1\n",
    "        self.transitions = [] \n",
    "        self.isTerminatingState = False \n",
    "\n",
    "    def add_transition(self, destination, input):\n",
    "        self.transitions.append(Transition(destination, input))\n",
    "\n",
    "    def findTransitionByInput(self , input : str) :\n",
    "        transition : Transition \n",
    "        for transition in self.transitions : \n",
    "            if transition.input == input :\n",
    "                return True , transition.destination \n",
    "        return None , None \n",
    "\n",
    "    def to_dict(self):\n",
    "        state_dict = {\n",
    "            \"isTerminatingState\": self.isTerminatingState\n",
    "        }\n",
    "        for transition in self.transitions:\n",
    "            if transition.input in state_dict:\n",
    "                # If key already exists, append to the list of destinations\n",
    "                if isinstance(state_dict[transition.input], list):\n",
    "                    state_dict[transition.input].append(transition.destination.state_name)\n",
    "                else:\n",
    "                    # If it's not already a list, make it a list\n",
    "                    state_dict[transition.input] = [state_dict[transition.input], transition.destination.state_name]\n",
    "            else:\n",
    "                # If key doesn't exist, add it\n",
    "                state_dict[transition.input] = transition.destination.state_name\n",
    "        return state_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "class NFA:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.start_state:State = None \n",
    "        #TODO : is this list or one element \n",
    "        self.accept_states : List [State] = []\n",
    "\n",
    "    def add_states(self, states: Union[List[State], List[List[State]]]):\n",
    "        # Flatten the list of lists if necessary\n",
    "        def flatten(states_list: List[Union[State, List[State]]]) -> List[State]:\n",
    "            flat_list = []\n",
    "            for state in states_list:\n",
    "                if isinstance(state, list):\n",
    "                    flat_list.extend(flatten(state))\n",
    "                else:\n",
    "                    flat_list.append(state)\n",
    "            return flat_list\n",
    "\n",
    "        states = flatten(states)\n",
    "        # Ensure every state.isTerminatingState = False\n",
    "        for state in states:\n",
    "            state.isTerminatingState = False\n",
    "        \n",
    "        self.states.extend(states)\n",
    "        if not self.start_state and states:\n",
    "            self.start_state = states[0]\n",
    "        if states:\n",
    "            self.accept_states.append(states[-1])\n",
    "            states[-1].isTerminatingState = True\n",
    "\n",
    "        \n",
    "    def add_state(self, state , is_start = False , is_accept = False  ):\n",
    "        self.states.append(state)\n",
    "        if is_start:\n",
    "            self.start_state = state\n",
    "        if is_accept:\n",
    "            self.accept_states.append(state)\n",
    "        return state\n",
    "    \n",
    "    def to_dict(self):\n",
    "        nfa_dict = {\n",
    "            \"startingState\": self.start_state.state_name if self.start_state else None\n",
    "        }\n",
    "        for state in self.states:\n",
    "            nfa_dict[state.state_name] = state.to_dict()\n",
    "        return nfa_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally : Thomsons construction Algorithm \n",
    "'''\n",
    "\n",
    "def create_nfa_initial_states() : \n",
    "    start_state = State()\n",
    "    end_state = State()\n",
    "    end_state.isTerminatingState = True \n",
    "    return start_state , end_state\n",
    "    \n",
    "def alphanumeric_nfa(char) : \n",
    "    start_state , end_state = create_nfa_initial_states()\n",
    "    start_state.add_transition(end_state , char)\n",
    "    nfa = NFA() \n",
    "    nfa.add_states([start_state , end_state])\n",
    "    return nfa \n",
    "\n",
    "def zero_or_more_nfa(operand: NFA) : \n",
    "    new_start_state , new_end_state = create_nfa_initial_states()\n",
    "    new_start_state.add_transition(operand.start_state , '~')\n",
    "    new_start_state.add_transition(new_end_state ,'~')\n",
    "    operand.accept_states[0].add_transition(operand.start_state ,'~')\n",
    "    operand.accept_states[0].add_transition(new_end_state,'~')\n",
    "    nfa = NFA ()\n",
    "    nfa.add_states([new_start_state , operand.states , new_end_state])\n",
    "    return nfa\n",
    "\n",
    "def union_nfa(operand1: NFA , operand2: NFA) :\n",
    "    new_start_state , new_end_state = create_nfa_initial_states()\n",
    "    new_start_state.add_transition(operand1.start_state , '~')\n",
    "    new_start_state.add_transition(operand2.start_state , '~')\n",
    "    operand1.accept_states[0].add_transition(new_end_state , '~')\n",
    "    operand2.accept_states[0].add_transition(new_end_state , '~')\n",
    "    nfa = NFA()\n",
    "    nfa.add_states([new_start_state , operand1.states , operand2.states , new_end_state])\n",
    "    return nfa\n",
    "\n",
    "def concatinate_nfa(operand1: NFA , operand2: NFA) :\n",
    "    operand1.accept_states[0].add_transition(operand2.start_state , '~')\n",
    "    nfa = NFA()\n",
    "    nfa.add_states([operand1.states , operand2.states])\n",
    "    return nfa\n",
    "\n",
    "def constructNFA(input ) : \n",
    "    stack_NFA = []\n",
    "    for char in input : \n",
    "        if char.isalnum() or char == '~' : \n",
    "            stack_NFA.append(alphanumeric_nfa(char))  \n",
    "        elif char == '*':\n",
    "            stack_NFA.append(zero_or_more_nfa(stack_NFA.pop()))\n",
    "        elif char == '|': \n",
    "            operand2 = stack_NFA.pop() \n",
    "            operand1 = stack_NFA.pop()\n",
    "            stack_NFA.append(union_nfa(operand1, operand2))\n",
    "        elif char == '?' :\n",
    "            operand2 = stack_NFA.pop() \n",
    "            operand1 = stack_NFA.pop()\n",
    "            stack_NFA.append(concatinate_nfa(operand1, operand2))\n",
    "\n",
    "    return stack_NFA[0] \n",
    "\n",
    "def ThomsonsConstruction (input : str) -> NFA : \n",
    "    preprocessed = preprocessing(input) \n",
    "    shunting_yard = shuntingYard(preprocessed)\n",
    "    return constructNFA(shunting_yard)  \n",
    "nfa = ThomsonsConstruction('0|1(1|0)*00')\n",
    "nfa_json = nfa.to_dict()\n",
    "# Print the JSON-formatted string\n",
    "#print(json.dumps(nfa_json, indent=2))\n",
    "visualize_nfa(nfa_json)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"startingState\": \"S0,S16,S2\",\n",
      "  \"S0,S16,S2\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S10,S11,S12,S3,S4,S6,S8\",\n",
      "    \"0\": \"S1,S17\"\n",
      "  },\n",
      "  \"S10,S11,S12,S3,S4,S6,S8\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S11,S12,S13,S14,S4,S6,S7,S8,S9\",\n",
      "    \"1\": \"S11,S12,S4,S5,S6,S8,S9\"\n",
      "  },\n",
      "  \"S1,S17\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S11,S12,S13,S14,S4,S6,S7,S8,S9\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S11,S12,S4,S5,S6,S8,S9\",\n",
      "    \"0\": \"S11,S12,S13,S14,S15,S17,S4,S6,S7,S8,S9\"\n",
      "  },\n",
      "  \"S11,S12,S4,S5,S6,S8,S9\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S11,S12,S13,S14,S4,S6,S7,S8,S9\",\n",
      "    \"1\": \"S11,S12,S4,S5,S6,S8,S9\"\n",
      "  },\n",
      "  \"S11,S12,S13,S14,S15,S17,S4,S6,S7,S8,S9\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"1\": \"S11,S12,S4,S5,S6,S8,S9\",\n",
      "    \"0\": \"S11,S12,S13,S14,S15,S17,S4,S6,S7,S8,S9\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"startingState\": \"S0\",\n",
      "  \"S0\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S1\",\n",
      "    \"0\": \"S2\"\n",
      "  },\n",
      "  \"S1\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S3\",\n",
      "    \"1\": \"S4\"\n",
      "  },\n",
      "  \"S2\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S3\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S5\"\n",
      "  },\n",
      "  \"S4\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S3\",\n",
      "    \"1\": \"S4\"\n",
      "  },\n",
      "  \"S5\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S5\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NFA to DFA \n",
    "\n",
    "'''\n",
    "class DFAState:\n",
    "    def __init__(self, nfa_states: Set[State]):\n",
    "        self.nfa_states = nfa_states\n",
    "        self.transitions: Dict[str, 'DFAState'] = {}\n",
    "        self.isTerminatingState = any(state.isTerminatingState for state in nfa_states)\n",
    "        self.state_name = ','.join(sorted(state.state_name for state in nfa_states))\n",
    "\n",
    "    def add_transition(self, input: str, destination: 'DFAState'):\n",
    "        self.transitions[input] = destination\n",
    "    def get_transitions_inputs(self) :\n",
    "        inputs = [] \n",
    "        transition: Transition\n",
    "        for transition in self.transitions :\n",
    "            inputs.append(transition.input)\n",
    "        return input\n",
    "    \n",
    "    def to_dict(self):\n",
    "        state_dict = {\n",
    "            \"isTerminatingState\": self.isTerminatingState\n",
    "        }\n",
    "        for input, destination in self.transitions.items():\n",
    "            state_dict[input] = destination.state_name\n",
    "        return state_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "class DFA:\n",
    "    def __init__(self):\n",
    "        self.states: List[DFAState] = []\n",
    "        self.start_state: DFAState = None\n",
    "\n",
    "    def add_state(self, state: DFAState, is_start=False):\n",
    "        self.states.append(state)\n",
    "        if is_start:\n",
    "            self.start_state = state\n",
    "    def find_DFA_state_by_NFA_states(self, nfa_states: Set[State]) -> Optional[DFAState]:\n",
    "        for dfa_state in self.states:\n",
    "            if dfa_state.nfa_states == nfa_states:\n",
    "                return dfa_state\n",
    "        return None\n",
    "    def to_dict(self):\n",
    "        dfa_dict = {\n",
    "            \"startingState\": self.start_state.state_name if self.start_state else False\n",
    "        }\n",
    "        for state in self.states:\n",
    "            dfa_dict[state.state_name] = state.to_dict()\n",
    "        return dfa_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "# nfa = ThomsonsConstruction('a(c|d)b*')\n",
    "\n",
    "def epsilonClosure(state : State) -> Set[State] :\n",
    "    states : Set[State] = {state} \n",
    "    transition : Transition \n",
    "\n",
    "   \n",
    "    for transition in state.transitions : \n",
    "        if transition.input == '~':\n",
    "            states.add(transition.destination)\n",
    "            states.update(epsilonClosure(transition.destination))\n",
    "\n",
    "    return states \n",
    "\n",
    "\n",
    "def subsetConstruction(nfa : NFA) -> NFA :\n",
    "    \n",
    "    dfa = DFA()\n",
    "    start_dfa_state = DFAState(epsilonClosure(nfa.start_state)  ) \n",
    "    dfa.add_state(start_dfa_state , is_start = True)\n",
    "    work_list = [start_dfa_state] \n",
    "    while (work_list):\n",
    "        transition : Transition\n",
    "        transitions_dict: Dict[str, List[State]] = {} \n",
    "        current_dfa_state = work_list.pop() \n",
    "        #  if current_dfa_state in processed_states:\n",
    "        #     continue\n",
    "        # processed_states.add(current_dfa_state)\n",
    "\n",
    "\n",
    "        for state in current_dfa_state.nfa_states :\n",
    "            for transition in state.transitions : \n",
    "                if transition.input != '~':\n",
    "                    if transition.input not in transitions_dict.keys() :\n",
    "                        transitions_dict[transition.input] = [transition.destination]\n",
    "                    else : \n",
    "                        transitions_dict[transition.input].append(transition.destination)\n",
    "       \n",
    "       # print(\"dictionary of transitions :\",transitions_dict)\n",
    "        for key , value in transitions_dict.items() : \n",
    "            epsilon_closures : Set[State] = set()\n",
    "\n",
    "            for nfa_state in value : \n",
    "                epsilon_closures.update(epsilonClosure(nfa_state))\n",
    "\n",
    "            existing_dfa_state = dfa.find_DFA_state_by_NFA_states(epsilon_closures)\n",
    "            if existing_dfa_state is None:\n",
    "                new_dfa_state = DFAState(epsilon_closures)\n",
    "                dfa.add_state(new_dfa_state)\n",
    "                work_list.append(new_dfa_state)\n",
    "            else:\n",
    "                new_dfa_state = existing_dfa_state\n",
    "\n",
    "            current_dfa_state.add_transition(key, new_dfa_state)\n",
    "    return dfa \n",
    "dfa = subsetConstruction(nfa) \n",
    "print (dfa)\n",
    "\n",
    "def renameDFA(dfa : DFA)-> DFA :\n",
    "    counter = 0\n",
    "    for state in dfa.states : \n",
    "        state.state_name = 'S'+ str(counter) \n",
    "        counter += 1\n",
    "    return dfa\n",
    "print(renameDFA(dfa))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "DFA Minimization \n",
    "'''\n",
    "def minimizeDFA(dfa : DFA) -> DFA: \n",
    "    #^ PASS 1 \n",
    "    # transition : Transition\n",
    "    # Step 1 : split groups into accepting and non accepting states\n",
    "    accepting_states : Set[DFAState] = set()\n",
    "    none_accepting_states : Set[DFAState] = set()\n",
    "    for state in dfa.states : \n",
    "        if state.isTerminatingState : \n",
    "            accepting_states.add(state)\n",
    "        else :\n",
    "            none_accepting_states.add(state)\n",
    "    groups : List[Set[DFAState]] = [accepting_states ,  none_accepting_states] \n",
    "    \n",
    "    #This function takes the list of all set of groups and returns\n",
    "    #the group number , : g1,g2,g3 and so on to be used in comparing and splitting\n",
    "    def get_group_index(state: DFAState, groups: List[Set[DFAState]]) -> int:\n",
    "        for i, group in enumerate(groups):\n",
    "            if state in group:\n",
    "                return i\n",
    "    '''\n",
    "    example output for this function : \n",
    "    transition_dict = {\n",
    "    (1, 2): {S1, S2},  # States S1 and S2 have identical transitions\n",
    "    (0, 0): {S3, S4}   # States S3 and S4 have identical transitions\n",
    "    }\n",
    "    each tuple corresponds to a transition and we are sure thet have same transitions\n",
    "    from pass 1 \n",
    "    '''\n",
    "    def create_transition_dict(subgroup: Set[DFAState],  groups: List[Set[DFAState]]) -> Dict[Tuple[int, ...], Set[DFAState]]:\n",
    "        transition_dict: Dict[Tuple[int, ...], Set[DFAState]] = {}\n",
    "        input_symbols: List[str] = list(subgroup)[0].get_transitions_inputs()\n",
    "        for state in subgroup :\n",
    "            transition_key_elements = []\n",
    "            for input_symbol in input_symbols:\n",
    "                destination_state = state.transitions[input_symbol]\n",
    "                # Get the index of the group to which the destination state belongs\n",
    "                group_index = get_group_index(destination_state, groups)\n",
    "                transition_key_elements.append(group_index)\n",
    "                transition_key = tuple(transition_key_elements)\n",
    "\n",
    "                # Group states by their transition pattern\n",
    "                if transition_key in transition_dict:\n",
    "                    transition_dict[transition_key].add(state)\n",
    "                else:\n",
    "                    transition_dict[transition_key] = {state}\n",
    "        return transition_dict\n",
    "\n",
    "\n",
    "\n",
    "    for group in groups : \n",
    "        transitions_dict: Dict[Tuple[str, ...], Set[str]] = {}\n",
    "        ''' \n",
    "        key             value \n",
    "        (a,b,c)         S0,S1,S2\n",
    "        (c,d,x)         S4,S9 \n",
    "\n",
    "        '''\n",
    "        # Step 2 : for every group , split it into subgroups based on their inputs  \n",
    "        for state in group:\n",
    "            transitions = tuple(state.get_transitions_inputs(state))  # Convert to tuple to use as dictionary key\n",
    "            if transitions in transitions_dict:\n",
    "                transitions_dict[transitions].add(state)\n",
    "            else:\n",
    "                transitions_dict[transitions] = [state] \n",
    "           \n",
    "        # Step 3 : delete the group and add the subgroups to groups list \n",
    "         \n",
    "        groups.remove(group)\n",
    "        for value in transitions_dict.values() :\n",
    "            groups.append(value)  \n",
    "            \n",
    "    #^ PASS TWO : \n",
    "    # Create a dictionary for each input in subgroup : \n",
    "    # now we are sure that every subgroup have same inputs\n",
    "    for group in groups : \n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "            # prev_state : DFAState = group[0]\n",
    "            # for transition in state :\n",
    "            #     does_prev_state_has_same_transition , prev_state_destination = prev_state.findTransitionByInput(transition.input)\n",
    "            #     if  does_prev_state_has_same_transition and get_group(prev_state_destination) == get_group(transition.destination) :\n",
    "            #             continue  # do nothing \n",
    "            #     else : \n",
    "            #         # move to new group keys: [input , dest] -> list of states that do the same thing \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
