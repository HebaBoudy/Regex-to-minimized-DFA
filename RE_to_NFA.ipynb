{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import json \n",
    "from typing import List , Union , Dict , Set ,Tuple, Optional\n",
    "from graphviz import Digraph\n",
    "import itertools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Helper Functions \n",
    " \n",
    "'''\n",
    "def split_input(input: str):\n",
    "    split_list = []\n",
    "    opening_match_found = False \n",
    "    match = \"\"\n",
    "    for char in input: \n",
    "        if char == '[' :\n",
    "            opening_match_found = True \n",
    "        elif char == ']': \n",
    "            opening_match_found = False \n",
    "            split_list.append('['+ match +']')\n",
    "            match = \"\" \n",
    "        elif  opening_match_found == 0 :\n",
    "            split_list.append (char) \n",
    "        else : \n",
    "            match =  match + char \n",
    "    return split_list\n",
    "\n",
    "def visualize_nfa(nfa_json):\n",
    "    # Create a new directed graph\n",
    "    dot = Digraph(format='png')\n",
    "    \n",
    "    # Set global graph attributes for visual clarity\n",
    "    dot.attr(rankdir='LR')  # Left to right layout\n",
    "\n",
    "    # Add states to the graph\n",
    "    start_state = nfa_json.get(\"startingState\")\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Determine if this state is an accepting state\n",
    "        is_accepting = state_info[\"isTerminatingState\"]\n",
    "\n",
    "        # Customize node style based on state type\n",
    "        if state_name == start_state:\n",
    "            dot.node(state_name, shape='circle', color='green', label=state_name)  # Start state\n",
    "        elif is_accepting:\n",
    "            dot.node(state_name, shape='doublecircle', color='blue', label=state_name)  # Accepting state\n",
    "        else:\n",
    "            dot.node(state_name, shape='circle', label=state_name)\n",
    "\n",
    "    # Add transitions\n",
    "    for state_name, state_info in nfa_json.items():\n",
    "        if state_name == \"startingState\":\n",
    "            continue\n",
    "\n",
    "        # Iterate over transitions and add them as edges\n",
    "        for input_symbol, destinations in state_info.items():\n",
    "            if input_symbol == \"isTerminatingState\":\n",
    "                continue\n",
    "            \n",
    "            if isinstance(destinations, list):\n",
    "                # If there are multiple destinations, create separate edges for each\n",
    "                for destination in destinations:\n",
    "                    label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                    dot.edge(state_name, destination, label=label)\n",
    "            else:\n",
    "                # Single destination, normal case\n",
    "                label = \"ε\" if input_symbol == \"~\" else input_symbol  # Represent epsilon with 'ε'\n",
    "                dot.edge(state_name, destinations, label=label)\n",
    "\n",
    "    # Render and view the graph\n",
    "    dot.render('nfa_graph', view=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "This preporcessing is applied to the regex before applying shunting yard algorithm in order to : \n",
    "1) reduce all the regex to these operations only ( * , | , parenthes , concat )\n",
    "2) add a concatination symbol between characters to be recognized by the algorithm as an operator \n",
    "3) replace every [match] with one char to be treated as other alphanumeric \n",
    "'''  \n",
    "def preprocessing(input : str) :\n",
    "# input= 'a?a((cd)|(a|b))b+bb' \n",
    "    #Step1: Replace zero or one symbol '?'\n",
    "    step_1 = re.sub(r'(\\w)\\?', r'(\\1|~)', input)\n",
    "    #Step2: Replace one or more symbol '+'\n",
    "    step_2 = re.sub(r'(\\w)\\+', r'\\1\\1*', step_1)\n",
    "    #Step3: Add concat symbol before every [ or (  if they are not at the start of the regex and they are not preceded by ?\n",
    "    pattern_before = re.compile(r'''\n",
    "        (?<!^)      # Negative lookbehind assertion to ensure the position is not at the start of the string\n",
    "        (?<!\\?)     # Negative lookbehind assertion to ensure the position is not preceded by '?'\n",
    "        (?=[\\[\\(])  # Positive lookahead assertion to match '[' or '(' without consuming them\n",
    "    ''', re.VERBOSE)\n",
    "    step_3 = pattern_before.sub('?', step_2) \n",
    "    #Step 4: Add concat symbol after every ] or ) if they are not the end of regex OR they are not followed by * and not followed by ? \n",
    "    pattern_after = re.compile(r'''\n",
    "        (?<=[\\]\\)])  # Positive lookbehind assertion to match ']' or ')' without consuming them\n",
    "        (?!$)        # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\*\\?])   # Negative lookahead assertion to ensure the position is not followed by '*' or '?'\n",
    "    ''', re.VERBOSE)\n",
    "    step_4 = pattern_after.sub('?', step_3)\n",
    "    #Step 5 : Add concat after every * if its not the end of regex and its not follwed by star \n",
    "    pattern_star = re.compile(r'''\n",
    "        \\*          # Match the '*' character\n",
    "        (?!$)       # Negative lookahead assertion to ensure the position is not at the end of the string\n",
    "        (?![\\?])    # Negative lookahead assertion to ensure the position is not followed by '?'                      \n",
    "    ''', re.VERBOSE)\n",
    "    step_5 = pattern_star.sub('*?', step_4)\n",
    "    #Step 6 : Add concat after every alphanum or dot if its followed by alphanumeric or dot \n",
    "    pattern_alnum_dot = re.compile(r'''\n",
    "        ([a-zA-Z0-9\\.])  # Match any alphanumeric character or dot\n",
    "        (?=[a-zA-Z0-9\\.])  # Positive lookahead assertion to ensure it is followed by another alphanumeric character or dot\n",
    "    ''', re.VERBOSE)\n",
    "    step_6 = pattern_alnum_dot.sub(r'\\1?', step_5)\n",
    "    return split_input(step_6) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Postfix notation removes the need for parentheses and allows computer programs to read in \n",
    "mathematical expressions one symbol after the other, instead of worrying about operator precedence \n",
    "and parentheses during computation. \n",
    "\n",
    "'''\n",
    "def shuntingYard(input) :\n",
    "    precedence_dict = {'*': 3, '?': 2, '|': 1}\n",
    "    out =[]\n",
    "    operator_stack = []\n",
    "    for char in input :\n",
    "        # If the input is alphanumeric then append to the output regex \n",
    "        if char.isalnum() or char == '.' or len(char) > 1 :\n",
    "            out.append(char)\n",
    "        # If the input is an operator\n",
    "        elif  char in precedence_dict.keys() :\n",
    "            # The first operator in the stack \n",
    "            if len(operator_stack) == 0:\n",
    "                operator_stack.append(char) \n",
    "            #  Any operator shouldn't be compared to an opening parenthes , if an opening parenthes is on the top of the stack Just add the char to the stack directly \n",
    "            elif operator_stack[-1] =='('or precedence_dict[ operator_stack[-1] ] < precedence_dict[char] :\n",
    "                operator_stack.append(char)\n",
    "            # If the operator on the top of the stack is the same as the current char then pop one to the output regex and leave the other in tha stack \n",
    "            # If two consecutive opening parenthes comes we need them both to be in the stack and not popped to the output because they will be deleted later \n",
    "            elif operator_stack[-1] != '(' and precedence_dict[ operator_stack[-1] ] == precedence_dict[char] : \n",
    "                out.append(char) \n",
    "            #If the operator at the top of the stack has higher precedence that the current operator then pop to the output until we can push the current operator to the stack \n",
    "            else : \n",
    "                while (len(operator_stack)>0 and operator_stack[-1] != '('and precedence_dict[ operator_stack[-1] ]  >= precedence_dict[char]) :\n",
    "                    popped_operator = operator_stack.pop()\n",
    "                    out.append(popped_operator)\n",
    "                operator_stack.append(char) \n",
    "        elif char == '(' :\n",
    "            operator_stack.append(char)\n",
    "        # The current char is closing parenthes -> pop from the operator stack to the output until you reach an opening parenthes\n",
    "        elif char == ')' :\n",
    "            while operator_stack:\n",
    "                operator = operator_stack.pop()\n",
    "                if operator == '(':\n",
    "                    break\n",
    "                out.append(operator)\n",
    "        # print (\"parsing char :\",char,\"output:\",out,\"stack\",operator_stack)\n",
    "        # print(\"************************\")\n",
    "    out.extend(operator_stack[::-1]) \n",
    "    # print (\"Final out :\",out)\n",
    "    return out \n",
    "\n",
    "    # print(\"Final stack :\",operator_stack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Datastructures defined\n",
    " \n",
    "'''\n",
    "class Transition:\n",
    "    def __init__(self, destination , input):\n",
    "        self.destination = destination\n",
    "        self.input = input\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Transition(destination={self.destination.state_name}, input='{self.input}')\"\n",
    "\n",
    "\n",
    "class State:\n",
    "    state_counter = 0  \n",
    "\n",
    "    def __init__(self):\n",
    "        self.state_name = 'S'+ str(State.state_counter) \n",
    "        State.state_counter += 1\n",
    "        self.transitions = [] \n",
    "        self.isTerminatingState = False \n",
    "\n",
    "    def add_transition(self, destination, input):\n",
    "        self.transitions.append(Transition(destination, input))\n",
    "\n",
    "    def findTransitionByInput(self , input : str) :\n",
    "        transition : Transition \n",
    "        for transition in self.transitions : \n",
    "            if transition.input == input :\n",
    "                return True , transition.destination \n",
    "        return None , None \n",
    "\n",
    "    def to_dict(self):\n",
    "        state_dict = {\n",
    "            \"isTerminatingState\": self.isTerminatingState\n",
    "        }\n",
    "        for transition in self.transitions:\n",
    "            if transition.input in state_dict:\n",
    "                # If key already exists, append to the list of destinations\n",
    "                if isinstance(state_dict[transition.input], list):\n",
    "                    state_dict[transition.input].append(transition.destination.state_name)\n",
    "                else:\n",
    "                    # If it's not already a list, make it a list\n",
    "                    state_dict[transition.input] = [state_dict[transition.input], transition.destination.state_name]\n",
    "            else:\n",
    "                # If key doesn't exist, add it\n",
    "                state_dict[transition.input] = transition.destination.state_name\n",
    "        return state_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "class NFA:\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.start_state:State = None \n",
    "        #TODO : is this list or one element \n",
    "        self.accept_states : List [State] = []\n",
    "\n",
    "    def add_states(self, states: Union[List[State], List[List[State]]]):\n",
    "        # Flatten the list of lists if necessary\n",
    "        def flatten(states_list: List[Union[State, List[State]]]) -> List[State]:\n",
    "            flat_list = []\n",
    "            for state in states_list:\n",
    "                if isinstance(state, list):\n",
    "                    flat_list.extend(flatten(state))\n",
    "                else:\n",
    "                    flat_list.append(state)\n",
    "            return flat_list\n",
    "\n",
    "        states = flatten(states)\n",
    "        # Ensure every state.isTerminatingState = False\n",
    "        for state in states:\n",
    "            state.isTerminatingState = False\n",
    "        \n",
    "        self.states.extend(states)\n",
    "        if not self.start_state and states:\n",
    "            self.start_state = states[0]\n",
    "        if states:\n",
    "            self.accept_states.append(states[-1])\n",
    "            states[-1].isTerminatingState = True\n",
    "\n",
    "        \n",
    "    def add_state(self, state , is_start = False , is_accept = False  ):\n",
    "        self.states.append(state)\n",
    "        if is_start:\n",
    "            self.start_state = state\n",
    "        if is_accept:\n",
    "            self.accept_states.append(state)\n",
    "        return state\n",
    "    \n",
    "    def to_dict(self):\n",
    "        nfa_dict = {\n",
    "            \"startingState\": self.start_state.state_name if self.start_state else None\n",
    "        }\n",
    "        for state in self.states:\n",
    "            nfa_dict[state.state_name] = state.to_dict()\n",
    "        return nfa_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Finally : Thomsons construction Algorithm \n",
    "'''\n",
    "\n",
    "def create_nfa_initial_states() : \n",
    "    start_state = State()\n",
    "    end_state = State()\n",
    "    end_state.isTerminatingState = True \n",
    "    return start_state , end_state\n",
    "    \n",
    "def alphanumeric_nfa(char) : \n",
    "    start_state , end_state = create_nfa_initial_states()\n",
    "    start_state.add_transition(end_state , char)\n",
    "    nfa = NFA() \n",
    "    nfa.add_states([start_state , end_state])\n",
    "    return nfa \n",
    "\n",
    "def zero_or_more_nfa(operand: NFA) : \n",
    "    new_start_state , new_end_state = create_nfa_initial_states()\n",
    "    new_start_state.add_transition(operand.start_state , '~')\n",
    "    new_start_state.add_transition(new_end_state ,'~')\n",
    "    operand.accept_states[0].add_transition(operand.start_state ,'~')\n",
    "    operand.accept_states[0].add_transition(new_end_state,'~')\n",
    "    nfa = NFA ()\n",
    "    nfa.add_states([new_start_state , operand.states , new_end_state])\n",
    "    return nfa\n",
    "\n",
    "def union_nfa(operand1: NFA , operand2: NFA) :\n",
    "    new_start_state , new_end_state = create_nfa_initial_states()\n",
    "    new_start_state.add_transition(operand1.start_state , '~')\n",
    "    new_start_state.add_transition(operand2.start_state , '~')\n",
    "    operand1.accept_states[0].add_transition(new_end_state , '~')\n",
    "    operand2.accept_states[0].add_transition(new_end_state , '~')\n",
    "    nfa = NFA()\n",
    "    nfa.add_states([new_start_state , operand1.states , operand2.states , new_end_state])\n",
    "    return nfa\n",
    "\n",
    "def concatinate_nfa(operand1: NFA , operand2: NFA) :\n",
    "    operand1.accept_states[0].add_transition(operand2.start_state , '~')\n",
    "    nfa = NFA()\n",
    "    nfa.add_states([operand1.states , operand2.states])\n",
    "    return nfa\n",
    "\n",
    "def constructNFA(input ) : \n",
    "    stack_NFA = []\n",
    "    for char in input : \n",
    "        if char.isalnum() or char == '~' : \n",
    "            stack_NFA.append(alphanumeric_nfa(char))  \n",
    "        elif char == '*':\n",
    "            stack_NFA.append(zero_or_more_nfa(stack_NFA.pop()))\n",
    "        elif char == '|': \n",
    "            operand2 = stack_NFA.pop() \n",
    "            operand1 = stack_NFA.pop()\n",
    "            stack_NFA.append(union_nfa(operand1, operand2))\n",
    "        elif char == '?' :\n",
    "            operand2 = stack_NFA.pop() \n",
    "            operand1 = stack_NFA.pop()\n",
    "            stack_NFA.append(concatinate_nfa(operand1, operand2))\n",
    "\n",
    "    return stack_NFA[0] \n",
    "\n",
    "def ThomsonsConstruction (input : str) -> NFA : \n",
    "    preprocessed = preprocessing(input) \n",
    "    shunting_yard = shuntingYard(preprocessed)\n",
    "    return constructNFA(shunting_yard)  \n",
    "nfa = ThomsonsConstruction('0|1(0|1)*00')\n",
    "nfa_json = nfa.to_dict()\n",
    "# Print the JSON-formatted string\n",
    "#print(json.dumps(nfa_json, indent=2))\n",
    "visualize_nfa(nfa_json)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello {'1': {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S11,S12,S13,S14,S4,S5,S6,S8,S9\",\n",
      "  \"1\": \"S11,S12,S4,S6,S7,S8,S9\"\n",
      "}, '0': {\n",
      "  \"isTerminatingState\": true\n",
      "}}\n",
      "**************\n",
      "{\n",
      "  \"startingState\": \"S1\",\n",
      "  \"S1\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S2\",\n",
      "    \"0\": \"S3\"\n",
      "  },\n",
      "  \"S2\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S4\",\n",
      "    \"1\": \"S5\"\n",
      "  },\n",
      "  \"S3\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S4\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S6\",\n",
      "    \"1\": \"S5\"\n",
      "  },\n",
      "  \"S5\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"0\": \"S4\",\n",
      "    \"1\": \"S5\"\n",
      "  },\n",
      "  \"S6\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"0\": \"S6\",\n",
      "    \"1\": \"S5\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "NFA to DFA \n",
    "\n",
    "'''\n",
    "class DFAState:\n",
    "    def __init__(self, nfa_states: Set[State]):\n",
    "        self.nfa_states = nfa_states\n",
    "        self.transitions: Dict[str, 'DFAState'] = {}\n",
    "        self.isTerminatingState = any(state.isTerminatingState for state in nfa_states)\n",
    "        self.state_name = ','.join(sorted(state.state_name for state in nfa_states))\n",
    "\n",
    "    def add_transition(self, input: str, destination: 'DFAState'):\n",
    "        self.transitions[input] = destination\n",
    "    \n",
    "    def get_transitions_inputs(self) :\n",
    "        return tuple(sorted(self.transitions.keys()))\n",
    "    \n",
    "    def to_dict(self):\n",
    "        state_dict = {\n",
    "            \"isTerminatingState\": self.isTerminatingState\n",
    "        }\n",
    "        for input, destination in self.transitions.items():\n",
    "            state_dict[input] = destination.state_name\n",
    "        return state_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "class DFA:\n",
    "    def __init__(self):\n",
    "        self.states: List[DFAState] = []\n",
    "        self.start_state: DFAState = None\n",
    "\n",
    "    def add_state(self, state: DFAState, is_start=False):\n",
    "        self.states.append(state)\n",
    "        if is_start:\n",
    "            self.start_state = state\n",
    "    def find_DFA_state_by_NFA_states(self, nfa_states: Set[State]) -> Optional[DFAState]:\n",
    "        for dfa_state in self.states:\n",
    "            if dfa_state.nfa_states == nfa_states:\n",
    "                return dfa_state\n",
    "        return None\n",
    "    def to_dict(self):\n",
    "        dfa_dict = {\n",
    "            \"startingState\": self.start_state.state_name if self.start_state else False\n",
    "        }\n",
    "        for state in self.states:\n",
    "            dfa_dict[state.state_name] = state.to_dict()\n",
    "        return dfa_dict\n",
    "\n",
    "    def __repr__(self):\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "# nfa = ThomsonsConstruction('a(c|d)b*')\n",
    "\n",
    "def epsilonClosure(state : State) -> Set[State] :\n",
    "    states : Set[State] = {state} \n",
    "    transition : Transition \n",
    "\n",
    "   \n",
    "    for transition in state.transitions : \n",
    "        if transition.input == '~':\n",
    "            states.add(transition.destination)\n",
    "            states.update(epsilonClosure(transition.destination))\n",
    "\n",
    "    return states \n",
    "\n",
    "\n",
    "def subsetConstruction(nfa : NFA) -> NFA :\n",
    "    \n",
    "    dfa = DFA()\n",
    "    start_dfa_state = DFAState(epsilonClosure(nfa.start_state)  ) \n",
    "    dfa.add_state(start_dfa_state , is_start = True)\n",
    "    work_list = [start_dfa_state] \n",
    "    while (work_list):\n",
    "        transition : Transition\n",
    "        transitions_dict: Dict[str, List[State]] = {} \n",
    "        current_dfa_state = work_list.pop() \n",
    "        #  if current_dfa_state in processed_states:\n",
    "        #     continue\n",
    "        # processed_states.add(current_dfa_state)\n",
    "\n",
    "\n",
    "        for state in current_dfa_state.nfa_states :\n",
    "            for transition in state.transitions : \n",
    "                if transition.input != '~':\n",
    "                    if transition.input not in transitions_dict.keys() :\n",
    "                        transitions_dict[transition.input] = [transition.destination]\n",
    "                    else : \n",
    "                        transitions_dict[transition.input].append(transition.destination)\n",
    "       \n",
    "       # print(\"dictionary of transitions :\",transitions_dict)\n",
    "        for key , value in transitions_dict.items() : \n",
    "            epsilon_closures : Set[State] = set()\n",
    "\n",
    "            for nfa_state in value : \n",
    "                epsilon_closures.update(epsilonClosure(nfa_state))\n",
    "\n",
    "            existing_dfa_state = dfa.find_DFA_state_by_NFA_states(epsilon_closures)\n",
    "            if existing_dfa_state is None:\n",
    "                new_dfa_state = DFAState(epsilon_closures)\n",
    "                dfa.add_state(new_dfa_state)\n",
    "                work_list.append(new_dfa_state)\n",
    "            else:\n",
    "                new_dfa_state = existing_dfa_state\n",
    "\n",
    "            current_dfa_state.add_transition(key, new_dfa_state)\n",
    "    return dfa \n",
    "dfa = subsetConstruction(nfa) \n",
    "#print (dfa)\n",
    "\n",
    "def renameDFA(dfa : DFA)-> DFA :\n",
    "    counter = 1 #TODO : LET THIS COUNTER =0 ANA 3MLTO KDA BS 3SHAN BA TEST \n",
    "    for state in dfa.states : \n",
    "        state.state_name = 'S'+ str(counter) \n",
    "        counter += 1\n",
    "    return dfa\n",
    "print(\"hello\",(dfa.states[0].transitions))\n",
    "print(\"**************\")\n",
    "print(renameDFA(dfa)) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total groups before partinioning : 2\n",
      "=== Starting New Pass ===\n",
      "Iteration 2, group size: 4\n",
      "Transition dict for group 2: {(0, 2): {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S6\",\n",
      "  \"1\": \"S5\"\n",
      "}}, (2, 2): {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}}, (1, 2): {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S2\",\n",
      "  \"0\": \"S3\"\n",
      "}}}\n",
      "Transition key: (0, 2), states: {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S6\",\n",
      "  \"1\": \"S5\"\n",
      "}}\n",
      "Transition key: (2, 2), states: {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}}\n",
      "Transition key: (1, 2), states: {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S2\",\n",
      "  \"0\": \"S3\"\n",
      "}}\n",
      "New groups size: 5\n",
      "=== Starting New Pass ===\n",
      "Iteration 3, group size: 2\n",
      "Transition dict for group 3: {(2, 3): {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}}}\n",
      "Transition key: (2, 3), states: {{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"0\": \"S4\",\n",
      "  \"1\": \"S5\"\n",
      "}}\n",
      "New groups size: 5\n",
      "Groups have stabilized, exiting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{{\n",
       "    \"isTerminatingState\": true,\n",
       "    \"0\": \"S6\",\n",
       "    \"1\": \"S5\"\n",
       "  }},\n",
       " {{\n",
       "    \"isTerminatingState\": true\n",
       "  }},\n",
       " {{\n",
       "    \"isTerminatingState\": false,\n",
       "    \"0\": \"S6\",\n",
       "    \"1\": \"S5\"\n",
       "  }},\n",
       " {{\n",
       "    \"isTerminatingState\": false,\n",
       "    \"0\": \"S4\",\n",
       "    \"1\": \"S5\"\n",
       "  },\n",
       "  {\n",
       "    \"isTerminatingState\": false,\n",
       "    \"0\": \"S4\",\n",
       "    \"1\": \"S5\"\n",
       "  }},\n",
       " {{\n",
       "    \"isTerminatingState\": false,\n",
       "    \"1\": \"S2\",\n",
       "    \"0\": \"S3\"\n",
       "  }}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "DFA Minimization  without comments\n",
    "''' \n",
    "def get_group_index(state: DFAState, groups: List[Set[DFAState]]) -> int:\n",
    "        for i, group in enumerate(groups):\n",
    "            if state in group:\n",
    "                return i\n",
    "            \n",
    "def create_transition_dict(subgroup: Set[DFAState],  groups: List[Set[DFAState]]) -> Dict[Tuple[int, ...], Set[DFAState]]:\n",
    "\n",
    "    transition_dict: Dict[Tuple[int, ...], Set[DFAState]] = {}\n",
    "    input_symbols = list(subgroup)[0].get_transitions_inputs() \n",
    "    \n",
    "    for state in subgroup :\n",
    "        transition_key_elements = []\n",
    "        for input_symbol in input_symbols:\n",
    "            destination_state = state.transitions[input_symbol]\n",
    "            # Get the index of the group to which the destination state belongs\n",
    "            group_index = get_group_index(destination_state, groups)\n",
    "            transition_key_elements.append(group_index)\n",
    "            transition_key = tuple(transition_key_elements)\n",
    "        # Group states by their transition pattern\n",
    "        if transition_key in transition_dict:\n",
    "            transition_dict[transition_key].add(state)\n",
    "        else:\n",
    "            transition_dict[transition_key] = {state}\n",
    "    return transition_dict\n",
    "\n",
    "def partition_groups_based_on_transitions(groups : List[Set[DFAState]]) -> List[Set[DFAState]]:\n",
    "    new_groups : List[Set[DFAState]] =  [] \n",
    "    print(\"total groups before partinioning :\" ,len(groups))\n",
    "    for i, group in enumerate(groups) : \n",
    "        transitions_dict: Dict[Tuple[str, ...], Set[str]] = {}\n",
    "        for state in group:\n",
    "            transitions = state.get_transitions_inputs()\n",
    "            if transitions in transitions_dict:\n",
    "                transitions_dict[transitions].add(state)\n",
    "            else:\n",
    "                transitions_dict[transitions] = {state}\n",
    "       \n",
    "        for value in transitions_dict.values() :\n",
    "            new_groups.append(value) \n",
    "    #         print (\"**********************iteration\"+str(i)+\"************************\")\n",
    "    #         print(len(new_groups))\n",
    "    # print (\"old groups length :\",len(groups))\n",
    "    # print (\"new groups length\",len(new_groups)) \n",
    "    # print(\"dict:\\n\",transitions_dict)\n",
    "    # # for i,group in enumerate(new_groups) :\n",
    "    # #     print (\"**********************g\"+str(i)+\"************************\")\n",
    "    # #     print(group)\n",
    "    return new_groups\n",
    "\n",
    "def minimizeDFA(dfa : DFA) -> DFA: \n",
    "    # PASS 1 \n",
    "    accepting_states : Set[DFAState] = set()\n",
    "    none_accepting_states : Set[DFAState] = set()\n",
    "    for state in dfa.states : \n",
    "        if state.isTerminatingState : \n",
    "            accepting_states.add(state)\n",
    "        else :\n",
    "            none_accepting_states.add(state)\n",
    "    \n",
    "    groups : List[Set[DFAState]] = [accepting_states ,  none_accepting_states] \n",
    "    groups = partition_groups_based_on_transitions(groups)\n",
    "   \n",
    "    #^ PASS TWO : \n",
    "    while True:\n",
    "        new_groups: List[Set[DFAState]] = []\n",
    "        for i, group in enumerate(groups): \n",
    "            if(len(group) == 1):\n",
    "                new_groups.append(group)\n",
    "                continue \n",
    "            if(list(group)[0].get_transitions_inputs() == ()): # no transitions\n",
    "                new_groups.append(group)\n",
    "                continue\n",
    "            transition_dict = create_transition_dict(group, groups)\n",
    "            for  states in transition_dict.values():\n",
    "                new_groups.append(states)\n",
    "        if new_groups == groups:\n",
    "            print(\"Groups have stabilized, exiting.\")\n",
    "            break\n",
    "        groups = new_groups\n",
    "    return groups\n",
    "#print (minimizeDFA(dfa))\n",
    "print(len(minimizeDFA(dfa)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"startingState\": \"S1\",\n",
      "  \"S1\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S2\",\n",
      "    \"0\": \"S3\"\n",
      "  },\n",
      "  \"S2\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S5\"\n",
      "  },\n",
      "  \"S3\": {\n",
      "    \"isTerminatingState\": true\n",
      "  },\n",
      "  \"S4\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S5\"\n",
      "  },\n",
      "  \"S5\": {\n",
      "    \"isTerminatingState\": false,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S6\"\n",
      "  },\n",
      "  \"S6\": {\n",
      "    \"isTerminatingState\": true,\n",
      "    \"1\": \"S4\",\n",
      "    \"0\": \"S6\"\n",
      "  }\n",
      "}\n",
      "groups after pass1 :\n",
      " [{{\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S4\",\n",
      "  \"0\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S4\",\n",
      "  \"0\": \"S5\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S2\",\n",
      "  \"0\": \"S3\"\n",
      "}, {\n",
      "  \"isTerminatingState\": false,\n",
      "  \"1\": \"S4\",\n",
      "  \"0\": \"S6\"\n",
      "}}, [{\n",
      "  \"isTerminatingState\": true,\n",
      "  \"1\": \"S4\",\n",
      "  \"0\": \"S6\"\n",
      "}], [{\n",
      "  \"isTerminatingState\": true\n",
      "}]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[169], line 119\u001b[0m\n\u001b[0;32m    116\u001b[0m         groups \u001b[38;5;241m=\u001b[39m new_groups  \u001b[38;5;66;03m# Update groups for the next iteration\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m groups \n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mminimizeDFA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfa\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[169], line 110\u001b[0m, in \u001b[0;36mminimizeDFA\u001b[1;34m(dfa)\u001b[0m\n\u001b[0;32m    107\u001b[0m new_groups: List[Set[DFAState]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m groups:\n\u001b[1;32m--> 110\u001b[0m     transition_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_transition_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     new_groups\u001b[38;5;241m.\u001b[39mextend(transition_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# Check if the partitioning has stabilized (no changes)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[169], line 64\u001b[0m, in \u001b[0;36mminimizeDFA.<locals>.create_transition_dict\u001b[1;34m(subgroup, groups)\u001b[0m\n\u001b[0;32m     61\u001b[0m destination_state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mtransitions[input_symbol]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Get the index of the group to which the destination state belongs\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m group_index \u001b[38;5;241m=\u001b[39m \u001b[43mget_group_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdestination_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m transition_key_elements\u001b[38;5;241m.\u001b[39mappend(group_index)\n\u001b[0;32m     66\u001b[0m transition_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(transition_key_elements)\n",
      "Cell \u001b[1;32mIn[169], line 21\u001b[0m, in \u001b[0;36mminimizeDFA.<locals>.get_group_index\u001b[1;34m(state, groups)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_group_index\u001b[39m(state: DFAState, groups: List[Set[DFAState]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(groups):\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m group:\n\u001b[0;32m     23\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m i\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "''' \n",
    "DFA Minimization  with explanation\n",
    "'''\n",
    "def minimizeDFA(dfa : DFA) -> DFA: \n",
    "    print(dfa)\n",
    "    #^ PASS 1 \n",
    "    # transition : Transition\n",
    "    # Step 1 : split groups into accepting and non accepting states\n",
    "    accepting_states : Set[DFAState] = set()\n",
    "    none_accepting_states : Set[DFAState] = set()\n",
    "    for state in dfa.states : \n",
    "        if state.isTerminatingState : \n",
    "            accepting_states.add(state)\n",
    "        else :\n",
    "            none_accepting_states.add(state)\n",
    "    \n",
    "    groups : List[Set[DFAState]] = [accepting_states ,  none_accepting_states] \n",
    "    #This function takes the list of all set of groups and returns\n",
    "    #the group number , : g1,g2,g3 and so on to be used in comparing and splitting\n",
    "    def get_group_index(state: DFAState, groups: List[Set[DFAState]]) -> int:\n",
    "        for i, group in enumerate(groups):\n",
    "            if state in group:\n",
    "                return i\n",
    "    '''\n",
    "    example output for this function : \n",
    "    transition_dict = {\n",
    "    el input el wlany wadany group 1\n",
    "    el input el tany wdany group 2 \n",
    "\n",
    "    (1, 2): {S1, S2},  # States S1 and S2 have identical transitions\n",
    "    (0, 0): {S3, S4}   # States S3 and S4 have identical transitions\n",
    "    }\n",
    "    each tuple corresponds to a transition and we are sure thet have same transitions\n",
    "    from pass 1 \n",
    "    '''\n",
    "    def create_transition_dict(subgroup: Set[DFAState],  groups: List[Set[DFAState]]) -> Dict[Tuple[int, ...], Set[DFAState]]:\n",
    "        transition_dict: Dict[Tuple[int, ...], Set[DFAState]] = {}\n",
    "        # Get List of inputs in which all these states have by selecting any one of them\n",
    "        # I chose the first one for simplicity , hya msh far2a \n",
    "        #klhom 3ndhom nafs en inputs aslan men PASS 1 \n",
    "        #assume the inputs for this subgroup is (a,b,c)\n",
    "        #then every state in this subgroup goes to some destination \n",
    "        #on inputs a,b,c\n",
    "        input_symbols = list(subgroup)[0].get_transitions_inputs() \n",
    "        # loop on every state and see The destination of each symbol , let us take the first state for  example S0 : \n",
    "            #  S0.transitions[a] -> goes to group 1\n",
    "            #  S0.transitions[b] -> goes to group 5\n",
    "            #  S0.transitions[c] -> goes to group 6 \n",
    "            #  now we create a tuple key of (1,5,6) where each index xorresponsd to input symbol and the value is the group destination\n",
    "            # search in the dict if theres a key of the same values and order  : (1,5,6)\n",
    "                #if the key doesnt exist then create it with value S0 \n",
    "                    # dict . add (1,5,6) :{S0}\n",
    "                #else if the ke exist before , for example we have this : (1,5,6) :{S1} \n",
    "                #then this means that state S1 on input a went to g1 and in input b went to g5 and on input c went to g6\n",
    "                #so S1 and S0 are acting exactly the same \n",
    "                    # Add S0 to the entry found : (1,5,6) :{S0,S1}\n",
    "            #AND SO ON , AT THE END ALL STATES THAT ACTS THE SAME ARE TOGETHER IN ONE SET \n",
    "        for state in subgroup :\n",
    "            transition_key_elements = []\n",
    "            for input_symbol in input_symbols:\n",
    "                destination_state = state.transitions[input_symbol]\n",
    "                \n",
    "                # Get the index of the group to which the destination state belongs\n",
    "                group_index = get_group_index(destination_state, groups)\n",
    "                transition_key_elements.append(group_index)\n",
    "                transition_key = tuple(transition_key_elements)\n",
    "\n",
    "                # Group states by their transition pattern\n",
    "                if transition_key in transition_dict:\n",
    "                    transition_dict[transition_key].add(state)\n",
    "                else:\n",
    "                    transition_dict[transition_key] = {state}\n",
    "        return transition_dict\n",
    "\n",
    "\n",
    "    for group in groups : \n",
    "        transitions_dict: Dict[Tuple[str, ...], Set[str]] = {}\n",
    "        ''' \n",
    "        key             value \n",
    "        (a,b,c)         S0,S1,S2\n",
    "        (c,d,x)         S4,S9 \n",
    "\n",
    "        '''\n",
    "        # Step 2 : for every group , split it into subgroups based on their inputs  \n",
    "        for state in group:\n",
    "            transitions = state.get_transitions_inputs()\n",
    "            if transitions in transitions_dict:\n",
    "                transitions_dict[transitions].add(state)\n",
    "            else:\n",
    "                transitions_dict[transitions] = [state] \n",
    "           \n",
    "        # Step 3 : delete the group and add the subgroups to groups list \n",
    "         \n",
    "        groups.remove(group)\n",
    "        for value in transitions_dict.values() :\n",
    "            groups.append(value)  \n",
    "    print (\"groups after pass1 :\\n\",groups)        \n",
    "    #^ PASS TWO : \n",
    "    # Create a dictionary for each input in subgroup : \n",
    "    # now we are sure that every subgroup have same inputs\n",
    "    # Main minimization loop\n",
    "   \n",
    "        # makontesh 3arf a3ml for loop 3l groups 3shan kont b8yr fl length bt3ha \n",
    "        # also ana msh 3arfa hwa2af emta fa el mfrod tkon while mesh for \n",
    "        # 3mlt new groups to update feha then compare if no changes happened a break , otherwise wna ba update\n",
    "        # fe nafs el haga mkansh 3andy stop condition \n",
    "       #^ PASS TWO : \n",
    "    while True:\n",
    "        new_groups: List[Set[DFAState]] = []\n",
    "        print(\"=== Starting New Pass ===\")\n",
    "        for i, group in enumerate(groups):\n",
    "            if(len(group) == 1):\n",
    "                new_groups.append(group)\n",
    "                continue \n",
    "            if(list(group)[0].get_transitions_inputs() == ()): # no transitions\n",
    "                new_groups.append(group)\n",
    "                continue\n",
    "            print(f\"Iteration {i}, group size: {len(group)}\")\n",
    "            transition_dict = create_transition_dict(group, groups)\n",
    "            print(f\"Transition dict for group {i}: {transition_dict}\")\n",
    "            \n",
    "            # We will keep track of merged groups in new_groups\n",
    "            for transition_key, states in transition_dict.items():\n",
    "                print(f\"Transition key: {transition_key}, states: {states}\")\n",
    "                new_groups.append(states)\n",
    "\n",
    "        print(f\"New groups size: {len(new_groups)}\")\n",
    "        \n",
    "        if new_groups == groups:\n",
    "            print(\"Groups have stabilized, exiting.\")\n",
    "            break\n",
    "\n",
    "        groups = new_groups\n",
    "\n",
    "    return groups\n",
    "\n",
    "print (minimizeDFA(dfa))\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
